{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use `turkish-lm-tuner` to evaluate your model\n",
    "\n",
    "`turkish-lm-tuner` provides task specific metrics and evaluator for easier evaluation of fine-tuned language models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import task specific metrics\n",
    "\n",
    "`Evaluator` class provides task specific metrics for tasks. It takes two arguments: `task` and `metrics`. \n",
    "The supported tasks are:\n",
    "- `classification`\n",
    "- `summarization`\n",
    "- `paraphrasing`\n",
    "- `title_generation`\n",
    "- `nli`\n",
    "- `semantic_similarity`\n",
    "- `ner`\n",
    "- `pos_tagging`\n",
    "\n",
    "The supported metrics are:\n",
    "- `accuracy`\n",
    "- `precision`\n",
    "- `precision_weighted`\n",
    "- `recall`\n",
    "- `recall_weighted`\n",
    "- `f1`\n",
    "- `f1_macro`\n",
    "- `f1_micro`\n",
    "- `f1_weighted`\n",
    "- `pearsonr`\n",
    "- `bleu`\n",
    "- `meteor`\n",
    "- `rouge`\n",
    "- `ter`\n",
    "- `squad`\n",
    "- `seqeval`\n",
    "\n",
    "For example, to import metrics for `classification` task:\n",
    "\n",
    "```python\n",
    "from turkish_lm_tuner import Evaluator\n",
    "\n",
    "eval = Evaluator(task='classification')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute metrics\n",
    "\n",
    "Metrics are then computed by calling `compute_metrics` method of `Evaluator` class. `compute_metrics` method takes two arguments: `preds` and `labels`. `labels` is the ground truth labels and `preds` is the predicted labels.\n",
    "\n",
    "For example, to compute metrics for `classification` task:\n",
    "\n",
    "```python\n",
    "eval.compute_metrics([0, 0, 1, 1], [1, 0, 1, 1])\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
