{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4e2209db-c3b4-4371-b259-af20e5dcd69a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pysam\n",
    "import pandas as pd\n",
    "from Bio.Seq import Seq\n",
    "import Levenshtein as lev\n",
    "\n",
    "def load_primers(primer_file):\n",
    "    \"\"\"Load and prepare primers dataframe\"\"\"\n",
    "    primers_df = pd.read_csv(primer_file, sep=\"\\t\")\n",
    "    primers_df = primers_df.dropna(subset=['Forward', 'Reverse'])\n",
    "    longest_primer_length = max(\n",
    "        primers_df['Forward'].apply(len).max(), \n",
    "        primers_df['Reverse'].apply(len).max()\n",
    "    )\n",
    "    return primers_df, longest_primer_length\n",
    "\n",
    "def is_match(seq1, seq2, max_distance=2):\n",
    "    \"\"\"\n",
    "    Check for approx match using Levenshtein distance.\n",
    "    seq1: longer sequence to search in\n",
    "    seq2: primer sequence to find\n",
    "    max_distance: maximum allowed edit distance\n",
    "    \"\"\"\n",
    "    # Handle potential None or empty sequences\n",
    "    if not seq1 or not seq2:\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        # Slide the primer (seq2) across the sequence (seq1)\n",
    "        for i in range(len(seq1) - len(seq2) + 1):\n",
    "            window = seq1[i:i+len(seq2)]\n",
    "            if len(window) == len(seq2):  # Ensure we have a full window\n",
    "                distance = lev.distance(str(window), str(seq2))\n",
    "                if distance <= max_distance:\n",
    "                    return True\n",
    "    except:\n",
    "        return False\n",
    "    return False\n",
    "\n",
    "def find_primers_in_region(sequence, primers_df, window_size=100, max_distance=2):\n",
    "    \"\"\"Find primers in a given sequence region\"\"\"\n",
    "    primers_found = []\n",
    "    \n",
    "    for _, primer in primers_df.iterrows():\n",
    "        forward_primer = primer['Forward']\n",
    "        reverse_primer = primer['Reverse']\n",
    "        reverse_complement_forward = str(Seq(forward_primer).reverse_complement())\n",
    "        reverse_complement_reverse = str(Seq(reverse_primer).reverse_complement())\n",
    "        \n",
    "        # Check each primer against the entire sequence\n",
    "        if is_match(sequence, forward_primer, max_distance):\n",
    "            primers_found.append(f\"{primer['Name']}_Forward\")\n",
    "            \n",
    "        if is_match(sequence, reverse_primer, max_distance):\n",
    "            primers_found.append(f\"{primer['Name']}_Reverse\")\n",
    "            \n",
    "        if is_match(sequence, reverse_complement_forward, max_distance):\n",
    "            primers_found.append(f\"{primer['Name']}_ForwardComp\")\n",
    "            \n",
    "        if is_match(sequence, reverse_complement_reverse, max_distance):\n",
    "            primers_found.append(f\"{primer['Name']}_ReverseComp\")\n",
    "    \n",
    "    return list(set(primers_found))  # Remove duplicates\n",
    "    \n",
    "def bam_to_fasta(bam_path, primer_file, unaligned_only=False, max_reads=200):\n",
    "    \"\"\"Process BAM file and find primers in reads\"\"\"\n",
    "    # Load primers\n",
    "    primers_df, longest_primer_length = load_primers(primer_file)\n",
    "    \n",
    "    # Open BAM file\n",
    "    try:\n",
    "        bam_file = pysam.AlignmentFile(bam_path, \"rb\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error opening BAM file: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    data = []\n",
    "    search_window = 100 + longest_primer_length  # Increased search window size\n",
    "    \n",
    "    reads_processed = 0\n",
    "    \n",
    "    for read in bam_file.fetch(until_eof=True):\n",
    "        if unaligned_only and not read.is_unmapped:\n",
    "            continue\n",
    "        if read.query_sequence is None:\n",
    "            continue\n",
    "\n",
    "        reads_processed += 1\n",
    "        \n",
    "        if max_reads > 0:\n",
    "            if reads_processed > max_reads:\n",
    "                break\n",
    "        \n",
    "        read_sequence = read.query_sequence\n",
    "        read_length = len(read_sequence)\n",
    "        \n",
    "        # print(f\"\\nProcessing read {reads_processed}:\")\n",
    "        # print(f\"Read name: {read.query_name}\")\n",
    "        # print(f\"Read length: {read_length}\")\n",
    "        \n",
    "        # Define search regions with bounds checking\n",
    "        start_region = read_sequence[:min(search_window, read_length)]\n",
    "        end_region = read_sequence[max(0, read_length - search_window):]\n",
    "        \n",
    "        # Find primers in both regions\n",
    "        start_primers_found = find_primers_in_region(start_region, primers_df, window_size=search_window, max_distance=2)\n",
    "        end_primers_found = find_primers_in_region(end_region, primers_df, window_size=search_window, max_distance=2)\n",
    "        \n",
    "        data.append({\n",
    "            'Read_Name': read.query_name,\n",
    "            'Start_Primers': ', '.join(start_primers_found) if start_primers_found else 'None',\n",
    "            'End_Primers': ', '.join(end_primers_found) if end_primers_found else 'None',\n",
    "            'Read_Length': read_length\n",
    "        })\n",
    "    \n",
    "    bam_file.close()\n",
    "    \n",
    "    result_df = pd.DataFrame(data)\n",
    "    return result_df\n",
    "\n",
    "\n",
    "def split_primer_results(result_df):\n",
    "    \"\"\"\n",
    "    Split results into three dataframes:\n",
    "    1. single_primer_df: Exactly one primer at each end\n",
    "    2. multiple_primer_df: More than one primer at either end\n",
    "    3. no_primer_df: No primers at either end\n",
    "    \"\"\"\n",
    "    \n",
    "    def count_primers(row):\n",
    "        \"\"\"Helper function to count primers in Start_Primers and End_Primers\"\"\"\n",
    "        start_count = 0 if row['Start_Primers'] == 'None' else row['Start_Primers'].count(',') + 1\n",
    "        end_count = 0 if row['End_Primers'] == 'None' else row['End_Primers'].count(',') + 1\n",
    "        return start_count, end_count\n",
    "\n",
    "    # Create mask for each category\n",
    "    single_primer_mask = result_df.apply(\n",
    "        lambda row: count_primers(row) == (1, 1), \n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    multiple_primer_mask = result_df.apply(\n",
    "        lambda row: any(count > 1 for count in count_primers(row)), \n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    no_primer_mask = result_df.apply(\n",
    "        lambda row: count_primers(row) == (0, 0), \n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # Split into three dataframes\n",
    "    single_primer_df = result_df[single_primer_mask].copy()\n",
    "    multiple_primer_df = result_df[multiple_primer_mask].copy()\n",
    "    no_primer_df = result_df[no_primer_mask].copy()\n",
    "    \n",
    "    # Add summary information\n",
    "    print(\"\\nSummary of split results:\")\n",
    "    print(f\"Reads with single primer at each end: {len(single_primer_df)}\")\n",
    "    print(f\"Reads with multiple primers at either end: {len(multiple_primer_df)}\")\n",
    "    print(f\"Reads with no primers: {len(no_primer_df)}\")\n",
    "    \n",
    "    print(\"\\nSingle primer reads:\")\n",
    "    print(single_primer_df)\n",
    "    \n",
    "    print(\"\\nMultiple primer reads:\")\n",
    "    print(multiple_primer_df)\n",
    "    \n",
    "    print(\"\\nNo primer reads:\")\n",
    "    print(no_primer_df)\n",
    "    \n",
    "    return single_primer_df, multiple_primer_df, no_primer_df\n",
    "    \n",
    "def analyze_primer_pairs(single_primer_df, primers_df):\n",
    "    \"\"\"\n",
    "    Analyze single primer matches for expected F/R pairs and size compliance\n",
    "    \"\"\"\n",
    "    # Helper function to extract primer name without orientation\n",
    "    def get_base_primer_name(primer_str):\n",
    "        if primer_str == 'None':\n",
    "            return None\n",
    "        # Split from the right side to preserve any underscores in the primer name\n",
    "        parts = primer_str.rsplit('_', 1)\n",
    "        return parts[0]  # Return everything except the last part (orientation)\n",
    "    \n",
    "    # Helper function to get primer orientation\n",
    "    def get_primer_orientation(primer_str):\n",
    "        if primer_str == 'None':\n",
    "            return None\n",
    "        return primer_str.rsplit('_', 1)[1]  # Get the last part (orientation)\n",
    "    \n",
    "    # Rest of the function remains the same\n",
    "    single_primer_df['Start_Primer_Name'] = single_primer_df['Start_Primers'].apply(get_base_primer_name)\n",
    "    single_primer_df['End_Primer_Name'] = single_primer_df['End_Primers'].apply(get_base_primer_name)\n",
    "    single_primer_df['Start_Orientation'] = single_primer_df['Start_Primers'].apply(get_primer_orientation)\n",
    "    single_primer_df['End_Orientation'] = single_primer_df['End_Primers'].apply(get_primer_orientation)\n",
    "    \n",
    "    # Find matching pairs (same primer name at both ends)\n",
    "    matching_pairs_df = single_primer_df[\n",
    "        single_primer_df['Start_Primer_Name'] == single_primer_df['End_Primer_Name']\n",
    "    ].copy()\n",
    "    \n",
    "    # Check correct orientation (one Forward, one Reverse)\n",
    "    correct_orientation_df = matching_pairs_df[\n",
    "        ((matching_pairs_df['Start_Orientation'].str.contains('Forward') & \n",
    "          matching_pairs_df['End_Orientation'].str.contains('Reverse')) |\n",
    "         (matching_pairs_df['Start_Orientation'].str.contains('Reverse') & \n",
    "          matching_pairs_df['End_Orientation'].str.contains('Forward')))\n",
    "    ].copy()\n",
    "    \n",
    "    # Add expected size information from primers_df\n",
    "    primer_sizes = primers_df.set_index('Name')['Size'].to_dict()\n",
    "    correct_orientation_df['Expected_Size'] = correct_orientation_df['Start_Primer_Name'].map(primer_sizes)\n",
    "    \n",
    "    # Calculate size compliance (within 10% of expected)\n",
    "    def is_size_compliant(row):\n",
    "        expected = row['Expected_Size']\n",
    "        actual = row['Read_Length']\n",
    "        if pd.isna(expected):\n",
    "            return False\n",
    "        tolerance = expected * 0.10  # 10% tolerance\n",
    "        return abs(actual - expected) <= tolerance\n",
    "    \n",
    "    correct_orientation_df['Size_Compliant'] = correct_orientation_df.apply(is_size_compliant, axis=1)\n",
    "    \n",
    "    return correct_orientation_df\n",
    "\n",
    "\n",
    "\n",
    "def create_analysis_summary(result_df, primers_df):\n",
    "    \"\"\"\n",
    "    Create a comprehensive summary of primer analysis results including mismatches and length statistics\n",
    "    \"\"\"\n",
    "    total_reads = len(result_df)\n",
    "    \n",
    "    # Helper functions for primer analysis with fixed underscore handling\n",
    "    def get_base_primer_name(primer_str):\n",
    "        if primer_str == 'None':\n",
    "            return None\n",
    "        return primer_str.rsplit('_', 1)[0]\n",
    "    \n",
    "    def get_primer_orientation(primer_str):\n",
    "        if primer_str == 'None':\n",
    "            return None\n",
    "        return primer_str.rsplit('_', 1)[1]\n",
    "    \n",
    "    result_df['Start_Primer_Name'] = result_df['Start_Primers'].apply(get_base_primer_name)\n",
    "    result_df['End_Primer_Name'] = result_df['End_Primers'].apply(get_base_primer_name)\n",
    "    result_df['Start_Orientation'] = result_df['Start_Primers'].apply(get_primer_orientation)\n",
    "    result_df['End_Orientation'] = result_df['End_Primers'].apply(get_primer_orientation)\n",
    "    \n",
    "    # Identify different categories\n",
    "    no_primers = result_df[\n",
    "        (result_df['Start_Primers'] == 'None') & \n",
    "        (result_df['End_Primers'] == 'None')\n",
    "    ]\n",
    "    \n",
    "    single_end_only = result_df[\n",
    "        ((result_df['Start_Primers'] != 'None') & (result_df['End_Primers'] == 'None')) |\n",
    "        ((result_df['Start_Primers'] == 'None') & (result_df['End_Primers'] != 'None'))\n",
    "    ]\n",
    "    \n",
    "    both_ends = result_df[\n",
    "        (result_df['Start_Primers'] != 'None') & \n",
    "        (result_df['End_Primers'] != 'None')\n",
    "    ]\n",
    "    \n",
    "    # Analyze matched pairs\n",
    "    matched_pairs = both_ends[\n",
    "        both_ends['Start_Primer_Name'] == both_ends['End_Primer_Name']\n",
    "    ]\n",
    "    \n",
    "    mismatched_pairs = both_ends[\n",
    "        both_ends['Start_Primer_Name'] != both_ends['End_Primer_Name']\n",
    "    ]\n",
    "    \n",
    "    # Check orientation and length compliance\n",
    "    primer_sizes = primers_df.set_index('Name')['Size'].to_dict()\n",
    "    \n",
    "    def is_correct_orientation(row):\n",
    "        return (\n",
    "            (row['Start_Orientation'].startswith('Forward') and \n",
    "             row['End_Orientation'].startswith('Reverse')) or\n",
    "            (row['Start_Orientation'].startswith('Reverse') and \n",
    "             row['End_Orientation'].startswith('Forward'))\n",
    "        )\n",
    "    \n",
    "    def is_size_compliant(row):\n",
    "        expected = primer_sizes.get(row['Start_Primer_Name'])\n",
    "        if pd.isna(expected):\n",
    "            return False\n",
    "        tolerance = expected * 0.10\n",
    "        return abs(row['Read_Length'] - expected) <= tolerance\n",
    "    \n",
    "    matched_pairs['Correct_Orientation'] = matched_pairs.apply(is_correct_orientation, axis=1)\n",
    "    matched_pairs['Size_Compliant'] = matched_pairs.apply(is_size_compliant, axis=1)\n",
    "    \n",
    "    # Create summary DataFrame\n",
    "    summary_data = [\n",
    "        {\n",
    "            'Category': 'No primers detected',\n",
    "            'Count': len(no_primers),\n",
    "            'Percentage': (len(no_primers) / total_reads) * 100\n",
    "        },\n",
    "        {\n",
    "            'Category': 'Single-end primers only',\n",
    "            'Count': len(single_end_only),\n",
    "            'Percentage': (len(single_end_only) / total_reads) * 100\n",
    "        },\n",
    "        {\n",
    "            'Category': 'Mismatched primer pairs',\n",
    "            'Count': len(mismatched_pairs),\n",
    "            'Percentage': (len(mismatched_pairs) / total_reads) * 100\n",
    "        },\n",
    "        {\n",
    "            'Category': 'Matched pairs - incorrect orientation',\n",
    "            'Count': len(matched_pairs[~matched_pairs['Correct_Orientation']]),\n",
    "            'Percentage': (len(matched_pairs[~matched_pairs['Correct_Orientation']]) / total_reads) * 100\n",
    "        },\n",
    "        {\n",
    "            'Category': 'Matched pairs - correct orientation, wrong size',\n",
    "            'Count': len(matched_pairs[\n",
    "                matched_pairs['Correct_Orientation'] & \n",
    "                ~matched_pairs['Size_Compliant']\n",
    "            ]),\n",
    "            'Percentage': (len(matched_pairs[\n",
    "                matched_pairs['Correct_Orientation'] & \n",
    "                ~matched_pairs['Size_Compliant']\n",
    "            ]) / total_reads) * 100\n",
    "        },\n",
    "        {\n",
    "            'Category': 'Matched pairs - correct orientation and size',\n",
    "            'Count': len(matched_pairs[\n",
    "                matched_pairs['Correct_Orientation'] & \n",
    "                matched_pairs['Size_Compliant']\n",
    "            ]),\n",
    "            'Percentage': (len(matched_pairs[\n",
    "                matched_pairs['Correct_Orientation'] & \n",
    "                matched_pairs['Size_Compliant']\n",
    "            ]) / total_reads) * 100\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    summary_df['Percentage'] = summary_df['Percentage'].round(2)\n",
    "    \n",
    "    return summary_df, matched_pairs, mismatched_pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "2db3f688-3380-426f-878a-88e8e3990272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Primer Analysis Summary:\n",
      "================================================================================\n",
      "                                       Category  Count  Percentage\n",
      "                            No primers detected  13944       13.63\n",
      "                        Single-end primers only  51519       50.37\n",
      "                        Mismatched primer pairs  17072       16.69\n",
      "          Matched pairs - incorrect orientation   2479        2.42\n",
      "Matched pairs - correct orientation, wrong size  17244       16.86\n",
      "   Matched pairs - correct orientation and size     26        0.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n5/6mvbv_f55bzgwm26x5l812w00000gn/T/ipykernel_61298/603153537.py:294: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  matched_pairs['Correct_Orientation'] = matched_pairs.apply(is_correct_orientation, axis=1)\n",
      "/var/folders/n5/6mvbv_f55bzgwm26x5l812w00000gn/T/ipykernel_61298/603153537.py:295: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  matched_pairs['Size_Compliant'] = matched_pairs.apply(is_size_compliant, axis=1)\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    try:\n",
    "        result_df = bam_to_fasta(\n",
    "            bam_path=\"test.bam\",\n",
    "            primer_file=\"primers.tsv\",\n",
    "            unaligned_only=False,\n",
    "            max_reads=0\n",
    "        )\n",
    "        \n",
    "        # Load primers for size information\n",
    "        primers_df, _ = load_primers(\"primers.tsv\")\n",
    "        \n",
    "        # Generate analysis summary\n",
    "        summary_df, matched_pairs, mismatched_pairs = create_analysis_summary(result_df, primers_df)\n",
    "        \n",
    "        # Print results\n",
    "        print(\"\\nPrimer Analysis Summary:\")\n",
    "        print(\"=\" * 80)\n",
    "        print(summary_df.to_string(index=False))\n",
    "        \n",
    "        # Save detailed results\n",
    "        matched_pairs.to_csv('matched_primer_pairs.csv', index=False)\n",
    "        mismatched_pairs.to_csv('mismatched_primer_pairs.csv', index=False)\n",
    "        # Save pairs with correct orientation but wrong size\n",
    "        wrong_size_pairs = matched_pairs[\n",
    "            matched_pairs['Correct_Orientation'] & \n",
    "            ~matched_pairs['Size_Compliant']\n",
    "        ]\n",
    "        wrong_size_pairs.to_csv('wrong_size_pairs.csv', index=False)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in main execution: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc59ca83-5315-4831-ad99-db3c2040dbb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57673a44-0111-4751-a615-f1e89dd57240",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4f7244-10d5-4c36-9854-6db7ead1fa7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abacd5e5-4a05-412b-a2d6-4baeef17e6d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
