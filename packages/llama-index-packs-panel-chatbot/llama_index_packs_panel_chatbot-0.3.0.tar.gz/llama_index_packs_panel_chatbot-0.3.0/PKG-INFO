Metadata-Version: 2.1
Name: llama-index-packs-panel-chatbot
Version: 0.3.0
Summary: llama-index packs panel_chatbot integration
License: MIT
Keywords: chatbot,github,index,openai,panel
Author: Your Name
Author-email: you@example.com
Maintainer: MarcSkovMadsen
Requires-Python: >=3.9,<4.0
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Requires-Dist: llama-index-core (>=0.12.0,<0.13.0)
Requires-Dist: llama-index-readers-github (>=0.5.0,<0.6.0)
Requires-Dist: nest-asyncio (>=1.6.0,<2.0.0)
Requires-Dist: panel (>=1.3.8,<2.0.0)
Description-Content-Type: text/markdown

# ðŸ¦™ Panel ChatBot Pack

Build a chatbot to talk to your Github repository.

Powered by LlamaIndex, OpenAI ChatGPT and [HoloViz Panel](https://panel.holoviz.org/reference/chat/ChatInterface.html).

![Panel Chat Bot](https://raw.githubusercontent.com/run-llama/llama-hub/main/llama_hub/llama_packs/panel_chatbot/panel_chatbot.png)

## ðŸ’â€â™€ï¸ Explanation

This template

- Downloads and indexes a Github repository using the `llama_index` [`GithubRepositoryReader`](https://llamahub.ai/l/github_repo). The default repository is [holoviz/panel](https://github.com/holoviz/panel).
- Creates a [VectorStoreIndex](https://docs.llamaindex.ai/en/stable/changes/deprecated_terms.html#VectorStoreIndex) powered chat engine that will retrieve context from that data to respond to each user query.
- Creates a Panel [`ChatInterface`](https://panel.holoviz.org/reference/chat/ChatInterface.html) UI that will stream each answer from the chat engine.

## ðŸ–¥ï¸ CLI Usage

You can download llamapacks directly using `llamaindex-cli`, which comes installed with the `llama-index` Python package:

```bash
pip install llama-index
llamaindex-cli download-llamapack PanelChatPack --download-dir ./panel_chat_pack
```

You can then inspect the files in the `panel_chat_pack` folder and use them as a template for your own project!

To run the app directly, use in your terminal:

```bash
export OPENAI_API_KEY="sk-..."
export GITHUB_TOKEN='...'
panel serve ./panel_chat_pack/base.py
```

As an alternative to `panel serve`, you can run

```bash
python ./panel_chat_pack/base.py
```

## ðŸŽ“ Learn More

- [`GithubRepositoryReader`](https://llamahub.ai/l/github_repo)
- [`VectorStoreIndex`](https://docs.llamaindex.ai/en/stable/changes/deprecated_terms.html#VectorStoreIndex)
- [Panel Chat Components](https://panel.holoviz.org/reference/index.html#chat)
- [Panel Chat Examples](https://github.com/holoviz-topics/panel-chat-examples)

## ðŸ‘ Credits

- [Marc Skov Madsen](https://twitter.com/MarcSkovMadsen) for creating the template
- [Sophia Yang](https://twitter.com/sophiamyang) for creating the cute LLama image.

## ðŸ“ˆ Potential Improvements

- [ ] Improved Multi-user support
  - [ ] Loading queue: Users should not be able to download the same repository at the same time.
- [ ] Service Context
  - [ ] Enable users to define the service context including `model`, `temperature` etc.
- [ ] Better loading experience
  - [ ] Let the chat assistant show (more fine-grained) status messages. And provide more status changes
- [ ] Focus on the streaming text
  - [ ] The streaming text is not always in focus. I believe its a matter of adjusting the `auto_scroll_limit` limit.
- [ ] Fix minor CSS issues
  - [ ] See the `CSS_FIXES_TO_BE_UPSTREAMED_TO_PANEL` variable in the code
- [ ] Repo Manager
  - [ ] Support using multiple repos. For example the full HoloViz suite

