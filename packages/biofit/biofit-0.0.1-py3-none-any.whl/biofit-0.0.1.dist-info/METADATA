Metadata-Version: 2.1
Name: biofit
Version: 0.0.1
Summary: BioFit: Bioinformatics Machine Learning Framework
Home-page: https://github.com/psmyth94/biofit
Author: Patrick Smyth
Author-email: psmyth1994@gmail.com
License: MIT
Download-URL: https://github.com/psmyth94/biofit/tags
Keywords: omics machine learning bioinformatics metrics
Platform: UNKNOWN
Classifier: Development Status :: 5 - Production/Stable
Classifier: Intended Audience :: Developers
Classifier: Intended Audience :: Education
Classifier: Intended Audience :: Science/Research
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: Topic :: Scientific/Engineering :: Bio-Informatics
Requires-Python: >=3.8.0,<3.12.0
Description-Content-Type: text/markdown
Requires-Dist: biocore>=1.1.1
Requires-Dist: filelock
Requires-Dist: numpy>=1.17
Requires-Dist: pyarrow>=8.0.0
Requires-Dist: pyarrow-hotfix
Requires-Dist: dill<0.3.8,>=0.3.0
Requires-Dist: pandas
Requires-Dist: requests>=2.19.0
Requires-Dist: tqdm>=4.62.1
Requires-Dist: xxhash
Requires-Dist: multiprocess
Requires-Dist: fsspec[http]<=2023.10.0,>=2023.1.0
Requires-Dist: packaging
Requires-Dist: pyyaml>=5.1
Requires-Dist: scikit-learn
Provides-Extra: all
Requires-Dist: matplotlib; extra == "all"
Requires-Dist: seaborn; extra == "all"
Requires-Dist: psutil; extra == "all"
Requires-Dist: polars>=0.20.5; extra == "all"
Requires-Dist: timezones>=0.10.2; extra == "all"
Requires-Dist: optuna; extra == "all"
Requires-Dist: lightgbm; extra == "all"
Requires-Dist: imbalanced-learn; extra == "all"
Requires-Dist: ruff>=0.1.5; extra == "all"
Requires-Dist: s3fs; extra == "all"
Provides-Extra: apache-beam
Requires-Dist: apache-beam<2.44.0,>=2.26.0; extra == "apache-beam"
Provides-Extra: docs
Requires-Dist: s3fs; extra == "docs"
Provides-Extra: jax
Requires-Dist: jax>=0.3.14; extra == "jax"
Requires-Dist: jaxlib>=0.3.14; extra == "jax"
Provides-Extra: ml
Requires-Dist: polars>=0.20.5; extra == "ml"
Requires-Dist: timezones>=0.10.2; extra == "ml"
Requires-Dist: optuna; extra == "ml"
Requires-Dist: lightgbm; extra == "ml"
Requires-Dist: imbalanced-learn; extra == "ml"
Provides-Extra: polars
Requires-Dist: polars>=0.20.5; extra == "polars"
Requires-Dist: timezones>=0.10.2; extra == "polars"
Provides-Extra: quality
Requires-Dist: ruff>=0.1.5; extra == "quality"
Provides-Extra: rpy2
Requires-Dist: rpy2>=3.5.15; extra == "rpy2"
Requires-Dist: rpy2-arrow>=0.0.8; extra == "rpy2"
Provides-Extra: s3
Requires-Dist: s3fs; extra == "s3"
Provides-Extra: tensorflow
Requires-Dist: tensorflow!=2.6.0,!=2.6.1,>=2.2.0; (sys_platform != "darwin" or platform_machine != "arm64") and extra == "tensorflow"
Requires-Dist: tensorflow-macos; (sys_platform == "darwin" and platform_machine == "arm64") and extra == "tensorflow"
Provides-Extra: tensorflow_gpu
Requires-Dist: tensorflow-gpu!=2.6.0,!=2.6.1,>=2.2.0; extra == "tensorflow-gpu"
Provides-Extra: test
Requires-Dist: ruff>=0.1.5; extra == "test"
Requires-Dist: pytest; extra == "test"
Requires-Dist: pytest-timeout; extra == "test"
Requires-Dist: pytest-xdist; extra == "test"
Requires-Dist: s3fs; extra == "test"
Requires-Dist: matplotlib; extra == "test"
Requires-Dist: seaborn; extra == "test"
Requires-Dist: psutil; extra == "test"
Requires-Dist: polars>=0.20.5; extra == "test"
Requires-Dist: timezones>=0.10.2; extra == "test"
Requires-Dist: optuna; extra == "test"
Requires-Dist: lightgbm; extra == "test"
Requires-Dist: imbalanced-learn; extra == "test"
Provides-Extra: torch
Requires-Dist: torch; extra == "torch"
Provides-Extra: vcf
Requires-Dist: cyvcf2>=0.30.0; extra == "vcf"
Requires-Dist: sgkit>=0.0.1; extra == "vcf"
Provides-Extra: viz
Requires-Dist: matplotlib; extra == "viz"
Requires-Dist: seaborn; extra == "viz"
Requires-Dist: psutil; extra == "viz"

<p align="center">
    $${\Huge{\textbf{\textsf{\color{#2E8B57}Bio\color{red}fit}}}}$$
    <br/>
    <br/>
</p>
<p align="center">
    <a href="https://github.com/psmyth94/biofit/actions/workflows/ci_cd_pipeline.yml?query=branch%3Amain"><img alt="Build" src="https://github.com/psmyth94/biofit/actions/workflows/ci_cd_pipeline.yml/badge.svg?branch=main"></a>
    <a href="https://github.com/psmyth94/biofit/blob/main/LICENSE"><img alt="GitHub" src="https://img.shields.io/github/license/psmyth94/biofit.svg?color=blue"></a>
    <a href="https://github.com/psmyth94/biofit/tree/main/docs"><img alt="Documentation" src="https://img.shields.io/website/http/github/psmyth94/biofit/tree/main/docs.svg?down_color=red&down_message=offline&up_message=online"></a>
    <a href="https://github.com/psmyth94/biofit/releases"><img alt="GitHub release" src="https://img.shields.io/github/release/psmyth94/biofit.svg"></a>
    <a href="CODE_OF_CONDUCT.md"><img alt="Contributor Covenant" src="https://img.shields.io/badge/Contributor%20Covenant-2.0-4baaaa.svg"></a>
    <!-- <a href="https://zenodo.org/records/14028772"><img src="https://zenodo.org/badge/DOI/10.5281/zenodo.14028772.svg" alt="DOI"></a> -->
</p>

**Biofit** is a machine learning library designed for bioinformatics datasets. It
provides tools for transforming, extracting, training, and evaluating machine learning
models on biomedical data. It also provides automatic data preprocessing, visualization,
and configurable processing pipelines. Here are some of the main features of Biofit:

- **Automatic Data Preprocessing:** Automatically preprocess biomedical datasets using
  built-in preprocessing steps.
- **Automatic Visualization:** Automatically visualize data using built-in visualization
  methods geared towards biomedical data.
- **Configurable Processing Pipelines:** Define and customize data processing pipelines.
- **Data Handling Flexibility:** Support for a wide range of data formats, including:
  - [Pandas](https://github.com/pandas-dev/pandas)
  - [Polars](https://github.com/pola-rs/polars)
  - [NumPy](https://github.com/numpy/numpy)
  - [CSR (SciPy)](https://github.com/scipy/scipy)
  - [Arrow](https://github.com/apache/arrow)
  - ðŸ¤— [Datasets](https://github.com/huggingface/datasets)
  - [Biosets](https://github.com/psmyth94/biosets)
- **Machine Learning Models:** Supports a wide range of machine learning models, including:
  - [Scikit-learn](https://github.com/scikit-learn/scikit-learn)
    - [Random Forest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)
    - [Support Vector Machine](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)
    - [Logistic Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)
    - [Lasso Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html)
  - [LightGBM](https://github.com/microsoft/LightGBM)
  - More to come!
- **Caching and Reuse:** Caches intermediate results using Apache Arrow for efficient reuse.
- **Batch Processing and Multiprocessing:** Utilize batch processing and multiprocessing for efficient handling of large-scale data.

## Installation

You can install Biofit via pip:

```bash
pip install biofit
```

## Quick Start

### Preprocessing Data

Biofit provides preprocessing capabilities tailored for omics data. You can use
built-in classes to load preprocessing steps based on the experiment type or create
custom preprocessing pipelines. The preprocessing pipeline in Biofit uses a syntax
similar to sklearn and supports distributed processing.

#### Using a Preprocessor

Biofit allows you to fit and transform your data in a few lines, similar to sklearn.
For example, you can use the LogTransformer to apply a log transformation to your data:

```python
from biofit.preprocessing import LogTransformer
import pandas as pd

dataset = pd.DataFrame({"feature1": [1, 2, 3, 4, 5]})
log_transformer = LogTransformer()
preprocessed_data = log_transformer.fit_transform(dataset)
# Applying log transformation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 7656.63 examples/s]
print(preprocessed_data)
#    feature1
# 0  0.000000
# 1  0.693147
# 2  1.098612
# 3  1.386294
# 4  1.609438
```

#### Auto Preprocessing

You can automatically apply standard preprocessing steps by specifying the experiment
type. This allows you to load tailored preprocessing steps for the type of data you are
working with, such as "otu", "asv", "snp", or "maldi":

```python
from biofit.preprocessing import AutoPreprocessor

preprocessor = AutoPreprocessor.for_experiment("snp", [{"min_prevalence": 0.1}, None])
print(preprocessor)
# [('min_prevalence_row', MinPrevalencFilter(min_prevalence=0.1)),
#  ('min_prevalence', MinPrevalenceFeatureSelector(min_prevalence=0.01))]

# Fit and transform the dataset using the preprocessor
preprocessed_data = preprocessor.fit_transform(dataset)
```

Biofit is made with [Biosets](https://github.com/psmyth94/biosets) in mind. You can
pass the loaded dataset instead of a string to load the preprocessors:

```python
from biosets import load_dataset

dataset = load_dataset("csv", data_files="my_file.csv", experiment_type="snp")

preprocessor = AutoPreprocessor.for_experiment(dataset)
print(preprocessor)
# [('min_prevalence_row', MinPrevalencFilter(min_prevalence=0.01)),
#  ('min_prevalence', MinPrevalenceFeatureSelector(min_prevalence=0.01))]
preprocessed_data = preprocessor.fit_transform(dataset)
```

#### Custom Preprocessing Pipeline

Biofit allows you to create custom preprocessing pipelines using the
`PreprocessorPipeline` class. This allows chaining multiple preprocessing steps from
`sklearn` and Biofit in a single operation:

```python
from biofit import load_dataset
from biofit.preprocessing import LogTransformer, PreprocessorPipeline
from sklearn.preprocessing import StandardScaler

# Load the dataset
dataset = load_dataset("csv", data_files="my_file.csv")

# Define a custom preprocessing pipeline
pipeline = PreprocessorPipeline(
    [("scaler", StandardScaler()), ("log_transformer", LogTransformer())]
)

# Fit and transform the dataset using the pipeline
preprocessed_data = pipeline.fit_transform(dataset.to_pandas())
```

For further details, check the [advance usage documentation](./docs/PREPROCESSING.md).

# License

Biofit is licensed under the Apache 2.0 License. See the [LICENSE](./LICENSE) file for
more information.

# Contributing

If you would like to contribute to Biofit, please read the
[CONTRIBUTING](./CONTRIBUTING.md) guidelines.


