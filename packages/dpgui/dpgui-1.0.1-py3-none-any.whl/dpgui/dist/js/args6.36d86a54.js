"use strict";(self["webpackChunkdpgui"]=self["webpackChunkdpgui"]||[]).push([[794],{1502:function(e){e.exports=JSON.parse('{"object":"Argument","name":"resources","type":["dict"],"optional":false,"alias":[],"doc":"","repeat":false,"sub_fields":{"number_node":{"object":"Argument","name":"number_node","type":["int"],"optional":true,"alias":[],"doc":"The number of node need for each `job`","repeat":false,"sub_fields":{},"sub_variants":{},"default":1},"cpu_per_node":{"object":"Argument","name":"cpu_per_node","type":["int"],"optional":true,"alias":[],"doc":"cpu numbers of each node assigned to each job.","repeat":false,"sub_fields":{},"sub_variants":{},"default":1},"gpu_per_node":{"object":"Argument","name":"gpu_per_node","type":["int"],"optional":true,"alias":[],"doc":"gpu numbers of each node assigned to each job.","repeat":false,"sub_fields":{},"sub_variants":{},"default":0},"queue_name":{"object":"Argument","name":"queue_name","type":["str"],"optional":true,"alias":[],"doc":"The queue name of batch job scheduler system.","repeat":false,"sub_fields":{},"sub_variants":{},"default":""},"group_size":{"object":"Argument","name":"group_size","type":["int"],"optional":false,"alias":[],"doc":"The number of `tasks` in a `job`. 0 means infinity.","repeat":false,"sub_fields":{},"sub_variants":{}},"custom_flags":{"object":"Argument","name":"custom_flags","type":["list"],"optional":true,"alias":[],"doc":"The extra lines pass to job submitting script header","repeat":false,"sub_fields":{},"sub_variants":{}},"strategy":{"object":"Argument","name":"strategy","type":["dict"],"optional":true,"alias":[],"doc":"strategies we use to generation job submitting scripts.","repeat":false,"sub_fields":{"if_cuda_multi_devices":{"object":"Argument","name":"if_cuda_multi_devices","type":["bool"],"optional":true,"alias":[],"doc":"If there are multiple nvidia GPUS on the node, and we want to assign the tasks to different GPUS.If true, dpdispatcher will manually export environment variable CUDA_VISIBLE_DEVICES to different task.Usually, this option will be used with Task.task_need_resources variable simultaneously.","repeat":false,"sub_fields":{},"sub_variants":{},"default":false},"ratio_unfinished":{"object":"Argument","name":"ratio_unfinished","type":["float"],"optional":true,"alias":[],"doc":"The ratio of `tasks` that can be unfinished.","repeat":false,"sub_fields":{},"sub_variants":{},"default":0},"customized_script_header_template_file":{"object":"Argument","name":"customized_script_header_template_file","type":["str"],"optional":true,"alias":[],"doc":"The customized template file to generate job submitting script header, which overrides the default file.","repeat":false,"sub_fields":{},"sub_variants":{}}},"sub_variants":{}},"para_deg":{"object":"Argument","name":"para_deg","type":["int"],"optional":true,"alias":[],"doc":"Decide how many tasks will be run in parallel.","repeat":false,"sub_fields":{},"sub_variants":{},"default":1},"source_list":{"object":"Argument","name":"source_list","type":["list"],"optional":true,"alias":[],"doc":"The env file to be sourced before the command execution.","repeat":false,"sub_fields":{},"sub_variants":{},"default":[]},"module_purge":{"object":"Argument","name":"module_purge","type":["bool"],"optional":true,"alias":[],"doc":"Remove all modules on HPC system before module load (module_list)","repeat":false,"sub_fields":{},"sub_variants":{},"default":false},"module_unload_list":{"object":"Argument","name":"module_unload_list","type":["list"],"optional":true,"alias":[],"doc":"The modules to be unloaded on HPC system before submitting jobs","repeat":false,"sub_fields":{},"sub_variants":{},"default":[]},"module_list":{"object":"Argument","name":"module_list","type":["list"],"optional":true,"alias":[],"doc":"The modules to be loaded on HPC system before submitting jobs","repeat":false,"sub_fields":{},"sub_variants":{},"default":[]},"envs":{"object":"Argument","name":"envs","type":["dict"],"optional":true,"alias":[],"doc":"The environment variables to be exported on before submitting jobs","repeat":false,"sub_fields":{},"sub_variants":{},"default":{}},"prepend_script":{"object":"Argument","name":"prepend_script","type":["list"],"optional":true,"alias":[],"doc":"Optional script run before jobs submitted.","repeat":false,"sub_fields":{},"sub_variants":{},"default":[]},"append_script":{"object":"Argument","name":"append_script","type":["list"],"optional":true,"alias":[],"doc":"Optional script run after jobs submitted.","repeat":false,"sub_fields":{},"sub_variants":{},"default":[]},"wait_time":{"object":"Argument","name":"wait_time","type":["int","float"],"optional":true,"alias":[],"doc":"The waitting time in second after a single `task` submitted","repeat":false,"sub_fields":{},"sub_variants":{},"default":0}},"sub_variants":{"batch_type":{"object":"Variant","flag_name":"batch_type","optional":false,"default_tag":"","choice_dict":{"Torque":{"object":"Argument","name":"Torque","type":["dict"],"optional":false,"alias":["torque"],"doc":"","repeat":false,"sub_fields":{"kwargs":{"object":"Argument","name":"kwargs","type":["dict"],"optional":true,"alias":[],"doc":"This field is empty for this batch.","repeat":false,"sub_fields":{},"sub_variants":{}}},"sub_variants":{}},"PBS":{"object":"Argument","name":"PBS","type":["dict"],"optional":false,"alias":["pbs"],"doc":"","repeat":false,"sub_fields":{"kwargs":{"object":"Argument","name":"kwargs","type":["dict"],"optional":true,"alias":[],"doc":"This field is empty for this batch.","repeat":false,"sub_fields":{},"sub_variants":{}}},"sub_variants":{}},"SlurmJobArray":{"object":"Argument","name":"SlurmJobArray","type":["dict"],"optional":false,"alias":["slurmjobarray"],"doc":"","repeat":false,"sub_fields":{"kwargs":{"object":"Argument","name":"kwargs","type":["dict"],"optional":true,"alias":[],"doc":"Extra arguments.","repeat":false,"sub_fields":{"custom_gpu_line":{"object":"Argument","name":"custom_gpu_line","type":["NoneType","str"],"optional":true,"alias":[],"doc":"Custom GPU configuration, starting with #SBATCH","repeat":false,"sub_fields":{},"sub_variants":{},"default":null},"slurm_job_size":{"object":"Argument","name":"slurm_job_size","type":["int"],"optional":true,"alias":[],"doc":"Number of tasks in a Slurm job","repeat":false,"sub_fields":{},"sub_variants":{},"default":1}},"sub_variants":{}}},"sub_variants":{}},"Fugaku":{"object":"Argument","name":"Fugaku","type":["dict"],"optional":false,"alias":["fugaku"],"doc":"","repeat":false,"sub_fields":{"kwargs":{"object":"Argument","name":"kwargs","type":["dict"],"optional":true,"alias":[],"doc":"This field is empty for this batch.","repeat":false,"sub_fields":{},"sub_variants":{}}},"sub_variants":{}},"DistributedShell":{"object":"Argument","name":"DistributedShell","type":["dict"],"optional":false,"alias":["distributedshell"],"doc":"","repeat":false,"sub_fields":{"kwargs":{"object":"Argument","name":"kwargs","type":["dict"],"optional":true,"alias":[],"doc":"This field is empty for this batch.","repeat":false,"sub_fields":{},"sub_variants":{}}},"sub_variants":{}},"Bohrium":{"object":"Argument","name":"Bohrium","type":["dict"],"optional":false,"alias":["bohrium","Lebesgue","lebesgue","DpCloudServer","dpcloudserver"],"doc":"","repeat":false,"sub_fields":{"kwargs":{"object":"Argument","name":"kwargs","type":["dict"],"optional":true,"alias":[],"doc":"This field is empty for this batch.","repeat":false,"sub_fields":{},"sub_variants":{}}},"sub_variants":{}},"SGE":{"object":"Argument","name":"SGE","type":["dict"],"optional":false,"alias":["sge"],"doc":"","repeat":false,"sub_fields":{"kwargs":{"object":"Argument","name":"kwargs","type":["dict"],"optional":true,"alias":[],"doc":"This field is empty for this batch.","repeat":false,"sub_fields":{},"sub_variants":{}}},"sub_variants":{}},"LSF":{"object":"Argument","name":"LSF","type":["dict"],"optional":false,"alias":["lsf"],"doc":"","repeat":false,"sub_fields":{"kwargs":{"object":"Argument","name":"kwargs","type":["dict"],"optional":false,"alias":[],"doc":"Extra arguments.","repeat":false,"sub_fields":{"gpu_usage":{"object":"Argument","name":"gpu_usage","type":["bool"],"optional":true,"alias":[],"doc":"Choosing if GPU is used in the calculation step. ","repeat":false,"sub_fields":{},"sub_variants":{},"default":false},"gpu_new_syntax":{"object":"Argument","name":"gpu_new_syntax","type":["bool"],"optional":true,"alias":[],"doc":"For LFS >= 10.1.0.3, new option -gpu for #BSUB could be used. If False, and old syntax would be used.","repeat":false,"sub_fields":{},"sub_variants":{},"default":false},"gpu_exclusive":{"object":"Argument","name":"gpu_exclusive","type":["bool"],"optional":true,"alias":[],"doc":"Only take effect when new syntax enabled. Control whether submit tasks in exclusive way for GPU.","repeat":false,"sub_fields":{},"sub_variants":{},"default":true},"custom_gpu_line":{"object":"Argument","name":"custom_gpu_line","type":["NoneType","str"],"optional":true,"alias":[],"doc":"Custom GPU configuration, starting with #BSUB","repeat":false,"sub_fields":{},"sub_variants":{},"default":null}},"sub_variants":{}}},"sub_variants":{}},"Shell":{"object":"Argument","name":"Shell","type":["dict"],"optional":false,"alias":["shell"],"doc":"","repeat":false,"sub_fields":{"kwargs":{"object":"Argument","name":"kwargs","type":["dict"],"optional":true,"alias":[],"doc":"This field is empty for this batch.","repeat":false,"sub_fields":{},"sub_variants":{}}},"sub_variants":{}},"Slurm":{"object":"Argument","name":"Slurm","type":["dict"],"optional":false,"alias":["slurm"],"doc":"","repeat":false,"sub_fields":{"kwargs":{"object":"Argument","name":"kwargs","type":["dict"],"optional":true,"alias":[],"doc":"Extra arguments.","repeat":false,"sub_fields":{"custom_gpu_line":{"object":"Argument","name":"custom_gpu_line","type":["NoneType","str"],"optional":true,"alias":[],"doc":"Custom GPU configuration, starting with #SBATCH","repeat":false,"sub_fields":{},"sub_variants":{},"default":null}},"sub_variants":{}}},"sub_variants":{}},"OpenAPI":{"object":"Argument","name":"OpenAPI","type":["dict"],"optional":false,"alias":["openapi"],"doc":"","repeat":false,"sub_fields":{"kwargs":{"object":"Argument","name":"kwargs","type":["dict"],"optional":true,"alias":[],"doc":"This field is empty for this batch.","repeat":false,"sub_fields":{},"sub_variants":{}}},"sub_variants":{}}},"choice_alias":{"torque":"Torque","pbs":"PBS","slurmjobarray":"SlurmJobArray","fugaku":"Fugaku","distributedshell":"DistributedShell","bohrium":"Bohrium","Lebesgue":"Bohrium","lebesgue":"Bohrium","DpCloudServer":"Bohrium","dpcloudserver":"Bohrium","sge":"SGE","lsf":"LSF","shell":"Shell","slurm":"Slurm","openapi":"OpenAPI"},"doc":"The batch job system type loaded from machine/batch_type."}}}')}}]);