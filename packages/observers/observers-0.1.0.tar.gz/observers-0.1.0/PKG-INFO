Metadata-Version: 2.1
Name: observers
Version: 0.1.0
Summary: ğŸ¤— Observers: The go-to library for AI and Generative AI observability, enabling insights into model interactions and everything that comes with it.
Author-Email: davidberenstein1957 <david.m.berenstein@gmail.com>
License: Apache 2
Requires-Python: >=3.10
Requires-Dist: duckdb>=1.1.3
Requires-Dist: datasets>=3.1.0
Requires-Dist: openai>=1.54.5
Requires-Dist: litellm>=1.52.10
Requires-Dist: llama-index>=0.12.0
Description-Content-Type: text/markdown

# llmdump

This is a lightweight library for tracking and syncing LLM completions to a local store and a Hugging Face dataset.

## Usage

### Tracking OpenAI Requests with `wrap_openai`

```python
from openai import OpenAI
import os

store = Store().connect()

api_key = os.environ["HF_INFERENCE_API_KEY"]
openai_client = OpenAI(base_url="https://api-inference.huggingface.co/v1/", api_key=api_key)

client = wrap_openai(openai_client, store=store)

response = client.chat.completions.create(
    model="Qwen/Qwen2.5-Coder-32B-Instruct",
    messages=[
        {"role": "user", "content": "Tell me a joke."}
    ],
)
```

### Viewing / Querying Local Store

The default store is [DuckDB](https://duckdb.org/) and can be viewed and queried using the [DuckDB CLI](https://duckdb.org/#quickinstall).

```bash
> duckdb store.db
> from openai_records limit 10;
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          id          â”‚        model         â”‚      timestamp       â”‚       messages       â”‚ â€¦ â”‚  error  â”‚     raw_response     â”‚ synced_at â”‚
â”‚       varchar        â”‚       varchar        â”‚      timestamp       â”‚ struct("role" varcâ€¦  â”‚   â”‚ varchar â”‚         json         â”‚ timestamp â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 89cb15f1-d902-4586â€¦  â”‚ Qwen/Qwen2.5-Coderâ€¦  â”‚ 2024-11-19 17:12:3â€¦  â”‚ [{'role': user, 'câ€¦  â”‚ â€¦ â”‚         â”‚ {"id": "", "choiceâ€¦  â”‚           â”‚
â”‚ 415dd081-5000-4d1aâ€¦  â”‚ Qwen/Qwen2.5-Coderâ€¦  â”‚ 2024-11-19 17:28:5â€¦  â”‚ [{'role': user, 'câ€¦  â”‚ â€¦ â”‚         â”‚ {"id": "", "choiceâ€¦  â”‚           â”‚
â”‚ chatcmpl-926         â”‚ llama3.1             â”‚ 2024-11-19 17:31:5â€¦  â”‚ [{'role': user, 'câ€¦  â”‚ â€¦ â”‚         â”‚ {"id": "chatcmpl-9â€¦  â”‚           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 3 rows                                                                                                                16 columns (7 shown) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

