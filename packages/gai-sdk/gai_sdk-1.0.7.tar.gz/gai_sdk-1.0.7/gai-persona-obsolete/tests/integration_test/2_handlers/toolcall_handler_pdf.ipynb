{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# use_TOOL_CALL_handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"LOG_LEVEL\"]=\"DEBUG\"\n",
    "\n",
    "# Create a function that returns a dictionary of tools.\n",
    "# Note that \n",
    "\n",
    "def create_tools_dict():\n",
    "    doc_titles=[\"REACT: SYNERGIZING REASONING AND ACTING IN LANGUAGE MODELS\"]\n",
    "    doc_keywords=[\"AI\",\"Reasoning\",\"LLM\"]\n",
    "    tools_dict={ \n",
    "        \"google\":{\n",
    "                \"type\": \"function\",\n",
    "                \"function\": {\n",
    "                    \"name\": \"google\",\n",
    "                    \"description\": \"The 'google' function is a powerful tool that allows the AI to gather external information from the internet using Google search. It can be invoked when the AI needs to answer a question or provide information that requires up-to-date, comprehensive, and diverse sources which are not inherently known by the AI. For instance, it can be used to find current news, weather updates, latest sports scores, trending topics, specific facts, or even the current date and time. The usage of this tool should be considered when the user's query implies or explicitly requests recent or wide-ranging data, or when the AI's inherent knowledge base may not have the required or most current information. The 'search_query' parameter should be a concise and accurate representation of the information needed.\",\n",
    "                    \"arguments\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"search_query\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"The search query to search google with. For example, to find the current date or time, use 'current date' or 'current time' respectively.\"\n",
    "                            }\n",
    "                        },\n",
    "                        \"required\": [\"search_query\"]\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "        \"retrieval\":{\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"retrieval\",\n",
    "                \"description\": f\"\"\"\n",
    "                    The `retrieval` function is a powerful tool that allows the AI to access articles outside of its knowledge domain from external sources. \n",
    "                    The external articles are stored in an archive and organised by <titles>:\\n{{ titles: [{doc_titles}] }}\n",
    "                    and <keywords>:\n",
    "                    {{ keywords: [{doc_keywords}] }}\n",
    "                    **IMPORTANT**: Use this tool when any of the <titles> or <keywords> may be relevant to user's question.\n",
    "                    The \\'search_query\\' parameter should be crafted in a way that it returns the most precise result based on the conversation context.\n",
    "                \"\"\",\n",
    "                \"arguments\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"search_query\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"\"\"The most effective search query for semantic search that will return the most precise result.\"\"\"\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"search_query\"]\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"text\": {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"text\",\n",
    "                \"description\": \"The 'text' function is the default catch-all function returned when none of the other tools are applicable.\",\n",
    "                \"arguments\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"message\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The user's message.\"\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"message\"]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    return tools_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gai.persona.fsm.handlers.use_TOOL_CALL_handler import use_TOOL_CALL_handler\n",
    "from gai.ttt.client.ttt_client import TTTClient\n",
    "ttt=TTTClient({\n",
    "    \"type\": \"ttt\",\n",
    "    \"url\": \"http://localhost:12031/gen/v1/chat/completions\",\n",
    "    \"temperature\":10e-9\n",
    "})\n",
    "from gai.lib.dialogue.MonologueMessageBuilder import MonologueMessageBuilder\n",
    "messages = MonologueMessageBuilder(\n",
    "    ).AddUserMessage(\"How does REACT differ from Chain-of-thought?\"\n",
    "    ).AddAssistantMessage(\n",
    "    ).BuildRoleMessages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[42m\u001b[30mINFO    \u001b[0m \u001b[32mon_GENERATE_handler:{\"type\": \"function\", \"name\": \"retrieval\", \"arguments\": \"{\\\"search_query\\\": \\\"REACT vs Chain-of-thought\\\"}\"}\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<font color=\"yellow\">{\"type\": \"function\", \"name\": \"retrieval\", \"arguments\": \"{\\\"search_query\\\": \\\"REACT vs Chain-of-thought\\\"}\"}</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "handler=use_TOOL_CALL_handler()\n",
    "handler.ttt=ttt\n",
    "handler.tools_dict=create_tools_dict()\n",
    "handler.tool_name=\"retrieval\"\n",
    "handler.monologue_messages=messages\n",
    "handler.max_new_tokens=300\n",
    "handler.max_tokens=300\n",
    "handler.on_TOOL_CALL()\n",
    "\n",
    "from gai.lib.common.notebook import highlight\n",
    "highlight(handler.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
