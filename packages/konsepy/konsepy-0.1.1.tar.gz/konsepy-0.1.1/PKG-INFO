Metadata-Version: 2.3
Name: konsepy
Version: 0.1.1
Summary: Framework for build NLP information extraction systems using regular expressions.
Keywords: nlp
Author-email: dcronkite <dcronkite+pypi@gmail.com>
Requires-Python: >=3.10
Description-Content-Type: text/markdown
Classifier: Development Status :: 5 - Production/Stable
Classifier: Intended Audience :: Science/Research
Classifier: Programming Language :: Python :: 3 :: Only
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Topic :: Text Processing :: Linguistic
Classifier: License :: OSI Approved :: MIT License
Classifier: Intended Audience :: Healthcare Industry
Requires-Dist: loguru
Requires-Dist: pytest
Requires-Dist: konsepy[sas, model] ; extra == "all"
Requires-Dist: datasets ; extra == "model"
Requires-Dist: transformers ; extra == "model"
Requires-Dist: sas7bdat ; extra == "sas"
Requires-Dist: spacy ; extra == "ssplit"
Project-URL: Home, https://github.com/kpwhri/konsepy
Provides-Extra: all
Provides-Extra: model
Provides-Extra: sas
Provides-Extra: ssplit


# konsepy

Framework for build NLP information extraction systems using regular expressions. `konsepy` then enables leveraging the NLP system to create a silver standard for fine-tuning a transformer model. 

## Installation

* `konsepy` is designed to be used with the [`knosepy_nlp_template`](https://github.com/kpwhri/konsepy_nlp_template)
  * See the README there for current installation instructions.
* To use `konsepy` as a standalone entity:
  * Install with `pip`:
    * `pip install konsepy[all]`
    * For sentence-splitting corpora from fine-tuning a sentence based transformer, `spacy` will also need to be installed and configured.

## Usage

For now, find documentation for this library (and a template to download) from https://github.com/kpwhri/konsepy_nlp_template.


## Roadmap

* Change labels to some metadata object to allow more diverse input sources and run info

